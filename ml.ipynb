{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tritonhacks/TritonHacks2025-ML-starter-kit/blob/main/ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fa7dd3",
      "metadata": {
        "id": "66fa7dd3"
      },
      "source": [
        "# TritonHacks 2025: Introduction to AI/ML Starter Kit Part II: Machine Learning (ML)\n",
        "\n",
        "Welcome to the Intro to AI/ML Starter Kit for TritonHacks 2025! This is the second of two notebooks in this repo, and it focuses on creating ML models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5336a773",
      "metadata": {
        "id": "5336a773"
      },
      "source": [
        "## Importing Libraries\n",
        "Like always, we will begin by importing libraries. In this notebook, we'll use SciKit-Learn to help us train our models. The library offers a wide variety of tools that will make the training process much easier. Feel free to check out the official documentation on [SciKit-Learn's Website](https://scikit-learn.org/stable/) to see how these functions work under the hood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "P9jRkTXCCN-9",
      "metadata": {
        "id": "P9jRkTXCCN-9"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data\n",
        "We'll also need to import our data. Check out `Importing Data` in the EDA file for more detailed instructions on this step."
      ],
      "metadata": {
        "id": "LrmIUifbLvQA"
      },
      "id": "LrmIUifbLvQA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Method #1: Direct Upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "path_to_file = 'healthcare-dataset-stroke-data.csv'"
      ],
      "metadata": {
        "id": "ItHcD3sHMKKA"
      },
      "id": "ItHcD3sHMKKA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3m13v5o-COlD",
      "metadata": {
        "id": "3m13v5o-COlD"
      },
      "outputs": [],
      "source": [
        "# Method #2: Mount Google Drive\n",
        "\n",
        "path_to_file = 'healthcare-dataset-stroke-data.csv' # REPLACE WITH PATH TO YOUR FILE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/MyDrive/' + path_to_file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path_to_file)"
      ],
      "metadata": {
        "id": "EuY2uK5ZMO5g"
      },
      "id": "EuY2uK5ZMO5g",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "Now, we need to get our data ready for training. In the EDA file, we identified explanatory variables and analyzed a few graphs showing the relationship between them. In this notebook, we will train our model on the following variables: gender, age, hypertension, heart disease, avg. glucose level, BMI, and smoking status. Feel free to play around with the selection to see which combination yield a better model."
      ],
      "metadata": {
        "id": "FljdtMeDMTyZ"
      },
      "id": "FljdtMeDMTyZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first remove the variables we don't need and look at the new dataframe:"
      ],
      "metadata": {
        "id": "D-A-vBdVNz1z"
      },
      "id": "D-A-vBdVNz1z"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['id', 'ever_married', 'work_type', 'Residence_type'], axis = 1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uBFjLEa1CvQs"
      },
      "id": "uBFjLEa1CvQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding\n",
        "Notice how entries in `gender` and `smoking_status` are formatted as *strings*. But wait, our ML model can't take strings as inputs! We need to perform **one-hot-encoding** (OHE) on the data to make sure all entries are expressed numerically. What this means is that each state a variable can take will be expressed as True/False or a set of 1s and 0s. Take `smoking_status` for instance–the variable can take on the values: formerly smoked, never smoked, smokes, or unknown. Once we OHE, we get the following values:\n",
        "\n",
        "<center>\n",
        "\n",
        "| | Formerly Smoked | Never Smoked | Smokes | Unknown | Status |\n",
        "|:-| :-: | :-: | :-: | :-: | :-:|\n",
        "|Person 1 | 1 | 0 | 0 | 0 | Formerly Smoked |\n",
        "|Person 2 | 0 | 1 | 0 | 0 | Never Smoked |\n",
        "|Person 3 | 0 | 0 | 1 | 0 | Smokes |\n",
        "|Person 4 | 0 | 0 | 0 | 1 | Unknown |\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "9wya3banN97X"
      },
      "id": "9wya3banN97X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's edit the dataframe to OHE both `gender` and `smoking_status`:"
      ],
      "metadata": {
        "id": "Jbi0xRa9St_G"
      },
      "id": "Jbi0xRa9St_G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_r1vzi_YMFBf",
      "metadata": {
        "id": "_r1vzi_YMFBf"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding\n",
        "\n",
        "one_hot = pd.get_dummies(\n",
        "    df,\n",
        "    columns=['gender', 'smoking_status'],\n",
        "    prefix=['gender', 'smoking']\n",
        ")\n",
        "df = one_hot\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to separate our explanatory and response variables. The explanatory variables (commonly denoted `X`) are used as inputs to train the model while the response variables (commonly denoted `y`) give us the actual values to tell us how good our model is."
      ],
      "metadata": {
        "id": "zkzAsio2TbmV"
      },
      "id": "zkzAsio2TbmV"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "PKAtGlehFP1a",
      "metadata": {
        "id": "PKAtGlehFP1a"
      },
      "outputs": [],
      "source": [
        "# Define X and y\n",
        "\n",
        "X = df.drop([\"stroke\"], axis = 1)\n",
        "y = df[\"stroke\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that in the EDA notebook, we discussed a few data normalization processes. We'll use SciKit-Learn's **Z-score normalization** to rescale `age`, `avg_glucose_level`, and `bmi` so that their values don't dominate the training process. (The variance in the values are larger so the ML model is more prone to fit along these variables and overlook others)."
      ],
      "metadata": {
        "id": "iRuHPFyQUwmU"
      },
      "id": "iRuHPFyQUwmU"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "mNVwrWtnSFVT",
      "metadata": {
        "id": "mNVwrWtnSFVT"
      },
      "outputs": [],
      "source": [
        "# Scaling dominant numeric features\n",
        "\n",
        "to_scale = ['age', 'avg_glucose_level', 'bmi']\n",
        "not_scaled = [col for col in X.columns if col not in to_scale]\n",
        "\n",
        "scaler = StandardScaler() # Z-score normalization\n",
        "scaled_part = scaler.fit_transform(X[to_scale])\n",
        "scaled_df = pd.DataFrame(scaled_part, columns=to_scale)\n",
        "\n",
        "X = pd.concat([scaled_df, X[not_scaled].reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split\n",
        "But wait, if we train our model on 100% of the data, how do we evaluate the quality of our model? We need the `train_test_split` function to divide the data into two batches. One batch is used to *train* the model and the other to *test* the model. Typically, the 70-80% of the data is allocated for training and the remaining 20-30% for testing."
      ],
      "metadata": {
        "id": "c30SMLQ4V70f"
      },
      "id": "c30SMLQ4V70f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, there's still a small issue...in the EDA notebook, we saw that the number of datapoints for non-stroke cases is significantly larger than the number of datapoints for stroke cases. On any given train-test split, there's a good chance that the majority of the data is just non-stroke cases. That's not very useful for our model because it doesn't learn to differentiate between stroke and non-stroke. To solve this imbalance in data, we will *undersample* the non-stroke class until we get roughly similar proportions between stroke/non-stroke cases."
      ],
      "metadata": {
        "id": "YlE9RRyqYqf_"
      },
      "id": "YlE9RRyqYqf_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dBKZwJ84CO_3",
      "metadata": {
        "id": "dBKZwJ84CO_3"
      },
      "outputs": [],
      "source": [
        "# Train-Test Spliting\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Model\n",
        "\n",
        "Let's start training models! The first machine learning model we will use will be called a linear classifier. Think of it like a linear equation you likely have seen from algebra class... but like an extension of it. Also, we use a classifier because we are predicting one of two outcomes: the patient either does or does not have a stroke. We aren't predicting some value, so we use `LogisticRegression` from `sklearn`. If you're trying to predict a value, use `LinearRegression` instead."
      ],
      "metadata": {
        "id": "G5zzhetIazZ4"
      },
      "id": "G5zzhetIazZ4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Classifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "linear_classifier = LogisticRegression()\n",
        "linear_classifier.fit(X_train, y_train)\n",
        "accuracy = (linear_classifier.predict(X_test) == y_test).mean()\n",
        "print(f'The linear classifier has a {accuracy * 100}% accuracy!')"
      ],
      "metadata": {
        "id": "9noDLxh1WNd4"
      },
      "id": "9noDLxh1WNd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision-Recall Curves (PR Curve)\n",
        "In the linear classifier, we quantified the performance of our model by looking at the proportion of predictions that were correct. Another way to analyze the quality of our model is using a precision-recall curve (PR curve). The graph plots the precision v. recall values for a given model at each decision threshold level.\n",
        "\n",
        "**Precision:**\n",
        "The precision measures the proportion of True Positives predicted by the model out of all positive predictions (True Positive + False Positive). It is calculated as:\n",
        "$$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
        "\n",
        "**Recall:**\n",
        "The recall measures the proportion of True Positives predicted by the model out of all *actual* positive values (True Positive + False Negative). It is given by:\n",
        "$$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
        "\n",
        "When we train a model, the model actually outputs its prediction as a probability. If the value is larger than the decision threshold of 0.5, the model outputs \"stroke\" and then vice versa otherwise. In a precision-recall curve, we vary this threshold value and observe how the precision and recall of the model respond. The area under the curve (AUC) represents how well the model performes."
      ],
      "metadata": {
        "id": "_bxgeKMtbMG9"
      },
      "id": "_bxgeKMtbMG9"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def precision_recall_score(X_data, y_data, model):\n",
        "  y_scores = model.predict_proba(X_test)[:, 1]\n",
        "  precision, recall, thresholds = precision_recall_curve(y_data, y_scores)\n",
        "  auc_score = auc(recall, precision)\n",
        "\n",
        "  # Plot precision-recall curve\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(recall, precision, label=f'Precision-Recall Curve (AUC = {auc_score:.2f})')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall Curve')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return precision, recall, auc_score"
      ],
      "metadata": {
        "id": "WV8Htli4CDr-"
      },
      "id": "WV8Htli4CDr-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors (KNN) Classifier\n",
        "\n",
        "Next, let's make a KNN Classifier. How does this ML model work? Think of every single patient we have as a data point in a plot, and each point has a color associated with whether that patient has a stroke or not. To figure out whether a new patient has a stroke or not, we turn it into a point with the other data points, and then we take a look at the `k` closest points to it, hence the name `k` nearest neighbors. Among those `k` points, if there are more points that represent patients with stroke than points that represent patients with no stroke, then we predict that our new patient has a stroke. If there are less, then we predict that our patient has no stroke. If there are equal, the decision may be decided by a coin flip (or you could just make the number of neighbors we look at an odd number)!\n",
        "\n",
        "Currently, we are looking at the nine closest neighbors. Feel free to play around with the number of neighbors (`n_neighbors`) and see what happens with the predictions!"
      ],
      "metadata": {
        "id": "L4uJCLXlgTQO"
      },
      "id": "L4uJCLXlgTQO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oS-ZuKebGT-d",
      "metadata": {
        "id": "oS-ZuKebGT-d"
      },
      "outputs": [],
      "source": [
        "# KNN Classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "KNN = KNeighborsClassifier(n_neighbors = 9)\n",
        "KNN.fit(X_train, y_train)\n",
        "y_predicted = KNN.predict(X_test)\n",
        "acc = accuracy_score(y_predicted, y_test)\n",
        "print(f'Accuracy: {acc}')\n",
        "\n",
        "precision, recall, auc_score = precision_recall_score(X_test, y_test, KNN)\n",
        "print(f'AUC Score: {auc_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier\n",
        "\n",
        "Another ML model we can make is the Decision Tree. You will eventually see a diagram of this, but the essence of how this works is that we ask a series of questions regarding patient info in order to determine whether the patient has a stroke or not.\n",
        "\n",
        "One crucial aspect of the Decision Tree is how deep you want to make the tree (`max_depth`). Currently, we have the depth of the tree set at 4, but feel free to play around with the number to see how this affects the predictions."
      ],
      "metadata": {
        "id": "3-TEbhSagZGM"
      },
      "id": "3-TEbhSagZGM"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "\n",
        "dt = DT(max_depth = 4, random_state = 42)\n",
        "dt.fit(X_train, y_train)\n",
        "accuracy = dt.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "precision, recall, auc_score = precision_recall_score(X_test, y_test, dt)\n",
        "print(f'AUC Score: {auc_score}')"
      ],
      "metadata": {
        "id": "pHcPMhAsjFee"
      },
      "id": "pHcPMhAsjFee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization"
      ],
      "metadata": {
        "id": "LAGbj0BsgcQC"
      },
      "id": "LAGbj0BsgcQC"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "dot_data = export_graphviz(dt, out_file=None, feature_names=X.columns, class_names=['Non-stroke', 'Stroke'], filled=True, rounded=True, special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "oF58TGVhjyt0"
      },
      "id": "oF58TGVhjyt0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest\n",
        "\n",
        "A Random Forest is essentially training a bunch of Decision Trees. Each Decision Tree takes a \"vote\" on whether a particular patient has a stroke or not. Our prediction is whichever decision receives the most votes.\n",
        "\n",
        "Like before, you can play around with the depth of each Decision Tree. However, the number of decision trees (`n_estimators`) could also affect the predictions. Try playing around with the number for it!"
      ],
      "metadata": {
        "id": "_bQmkGGWgzLP"
      },
      "id": "_bQmkGGWgzLP"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "\n",
        "rf = RF(n_estimators = 100, max_depth = 4, random_state = 0)\n",
        "rf.fit(X_train, y_train)\n",
        "accuracy = rf.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "precision, recall, auc_score = precision_recall_score(X_test, y_test, rf)\n",
        "print(f'AUC Score: {auc_score}')"
      ],
      "metadata": {
        "id": "-h8t_0LIiffu"
      },
      "id": "-h8t_0LIiffu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-layer Perceptron (MLP)\n",
        "A Multi-layer Perceptron, also known as a feedforward neural network, forms the basis for most deep learning algorithms. The model essential consists of layers of \"neurons\", where each neuron in layer $l$ is connected to every neuron in layer $l+1$. In the case of our MLP model, we will use 2 hidden layers of size 128 and 64 neurons respectively. Our input layer will have 13 neurons, one for each parameter we pass to the network. Since we are doing a binary classification task, we'll have 2 output neurons–one for predicting stroke and the other for predicting non-stroke. When we pass the input to the MLP, each neuron will perform a specific set of operations to the values (which we optimize when we train the model) before passing the output to neurons in the next layer. The process propagates through the network until it reaches the output neurons, where we determine which classification is more likely."
      ],
      "metadata": {
        "id": "pYGc851Zg17O"
      },
      "id": "pYGc851Zg17O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some Extra Info:**\n",
        "If you're wondering why MLP models are so common in deep learning, it's because these models allow us to approximate complicated functions as a set of non-linear transformations. Let's take a neuron $x_1$ in layer 1 which is connected to neuron $x_2$ in layer 2. The transition from $x_1$ to $x_2$ is given by: $$x_{1,2} = \\text{ReLU}(w_{1,2} * x_1 + b_{1,2})$$ If $w_{1,2} * x_1 + b_{1,2}$ looks familiar, you're right! It's a linear transformation of $x_1$. We call $w_{1,2}$ the weight between two neurons and $b_{1,2}$ the bias. When we train our model, we are specifically optimizing these values (through [backpropagation](https://en.wikipedia.org/wiki/Backpropagation)). The magic behind these models are *activation functions* like ReLU. The function is super simple $$ReLU(x) =\n",
        "\\begin{cases}\n",
        "0, & \\text{if } x \\leq 0 \\\\\n",
        "x, & \\text{if } x > 0\n",
        "\\end{cases}$$\n",
        "but it's nonlinear nature is key to allowing ML models to act as universal function approximators."
      ],
      "metadata": {
        "id": "nlY0L2NjaC2Q"
      },
      "id": "nlY0L2NjaC2Q"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes = (128, 64), max_iter = 1000, random_state = 0)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_predicted = mlp.predict(X_test)\n",
        "acc = accuracy_score(y_predicted, y_test)\n",
        "print(acc)\n",
        "\n",
        "precision, recall, auc_score = precision_recall_score(X_test, y_test, mlp)\n",
        "print(f'AUC Score: {auc_score}')"
      ],
      "metadata": {
        "id": "1PZtafMRWBTR"
      },
      "id": "1PZtafMRWBTR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that concludes the machine learning notebook! Feel free to try out one of these models for your project. The five ML models that we chose certainly aren't the only models out there, so consider checking out other ML models that you might want to make!"
      ],
      "metadata": {
        "id": "uENtFByohcQ7"
      },
      "id": "uENtFByohcQ7"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
